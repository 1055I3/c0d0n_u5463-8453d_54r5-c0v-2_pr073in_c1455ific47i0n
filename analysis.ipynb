{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadatak 2\n",
    "\n",
    "Izvršiti klasifikaciju tipova proteinskih sekvenci na osnovu upotrebe kodona kod SARS2\n",
    "koronavirusa\n",
    "\n",
    "- proteinske i kodirajuće sekvence preuzeti sa [NCBI Virus](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=SARS-CoV-2,%20taxid:2697049).\n",
    "\n",
    "- upotrebu kodona preuzeti sa [The Genetic Codes](https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi).\n",
    "Za SARS2 koristiti standardni kod (transl_table=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dtreeviz\n",
    "import dalex as dx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, balanced_accuracy_score, precision_recall_curve, confusion_matrix, classification_report\n",
    "\n",
    "from mlxtend.evaluate import RandomHoldoutSplit\n",
    "\n",
    "from openTSNE import TSNE\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn_genetic import ExponentialAdapter, GASearchCV\n",
    "from sklearn_genetic.callbacks import DeltaThreshold\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "\n",
    "stop = 5\n",
    "start = 7\n",
    "\n",
    "tous = 11\n",
    "pops = 31\n",
    "seed = 196883\n",
    "\n",
    "sample = 4224\n",
    "maxiter = np.iinfo(np.int32).max\n",
    "\n",
    "t_stop = 1e-4\n",
    "t_sample = 0.2\n",
    "\n",
    "a_rate = 0.1\n",
    "m_prob = 0.2\n",
    "c_prob = 0.8\n",
    "\n",
    "n_features = 7\n",
    "\n",
    "np.random.seed(seed)\n",
    "\n",
    "pio.renderers.default = 'notebook'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priprema podataka\n",
    "\n",
    "Učitavamo podatke sa jedinstvenim kodirajućim sekvencama proteina SARS-CoV-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('samo_jedinstvene_kodirajuce_sekvence.csv', header=None, on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izdvajamo kolonu sa kodirajućim sekvencama i kolonu sa oznakama tipova proteina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[14, 12]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Čišćenje podataka\n",
    "\n",
    "Proveravamo da li su kodirajuće sekvence odgovarajuće dužine.\n",
    "One koje nisu, odbacujemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.array([len(a) for a in df[14]])\n",
    "valid = (length > 8) & (length % 3 == 0)\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proveravamo da li se kodirajuće sekvence sastoje samo od slova A, T, C i G.\n",
    "Sekvence koje ne ispunjavaju ovaj uslov odbacujemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df[14].map(lambda a: set(a).issubset(set('ATCG')))\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proveravamo koliko instanci imamo u svakoj klasi.\n",
    "Odnosno koliko sekvenci imamo za svaki tip proteina.\n",
    "Klase koje sadrže 64 instanci i manje odbacujemo zajedno sa instancom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = df.groupby([12])[12].count()\n",
    "valid = np.array([proteins[a] for a in df[12]]) > 64\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon čišćenja podataka, od jedinstvenih 889737 kodirajućih ostalo nam je 869858 instanci.\n",
    "Ukupno 19879 instanci je odbačeno kao nevalidno, odnosno oko $2.23\\%$ skupa jedinstvenih kodirajućih sekvenci.\n",
    "\n",
    "### Izračunavanje upotrebe kodona\n",
    "\n",
    "Računamo koliko često neki kodon kodira svoju amino-kiselinu u svakoj kodirajućoj sekvenci.\n",
    "\n",
    "Potrebna nam je standardna tabela kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_codon_table = {\n",
    "    'TTT': 'F', 'TCT': 'S', 'TAT': 'Y', 'TGT': 'C',\n",
    "    'TTC': 'F', 'TCC': 'S', 'TAC': 'Y', 'TGC': 'C',\n",
    "    'TTA': 'L', 'TCA': 'S', 'TAA': 'O', 'TGA': 'O',\n",
    "    'TTG': 'L', 'TCG': 'S', 'TAG': 'O', 'TGG': 'W',\n",
    "\n",
    "    'CTT': 'L', 'CCT': 'P', 'CAT': 'H', 'CGT': 'R',\n",
    "    'CTC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R',\n",
    "    'CTA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R',\n",
    "    'CTG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R',\n",
    "\n",
    "    'ATT': 'I', 'ACT': 'T', 'AAT': 'N', 'AGT': 'S',\n",
    "    'ATC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S',\n",
    "    'ATA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R',\n",
    "    'ATG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R',\n",
    "\n",
    "    'GTT': 'V', 'GCT': 'A', 'GAT': 'D', 'GGT': 'G',\n",
    "    'GTC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G',\n",
    "    'GTA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G',\n",
    "    'GTG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potrebna nam je i inverzna tabela kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_codon_table = {\n",
    "    'F': ('TTT', 'TTC'),\n",
    "    'L': ('CTT', 'CTC', 'CTA', 'CTG', 'TTA', 'TTG'),\n",
    "    'I': ('ATT', 'ATC', 'ATA'),\n",
    "    'M': ('ATG', ),\n",
    "    'V': ('GTT', 'GTC', 'GTA', 'GTG'),\n",
    "    'S': ('TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'),\n",
    "    'P': ('CCT', 'CCC', 'CCA', 'CCG'),\n",
    "    'T': ('ACT', 'ACC', 'ACA', 'ACG'),\n",
    "    'A': ('GCT', 'GCC', 'GCA', 'GCG'),\n",
    "    'Y': ('TAT', 'TAC'),\n",
    "    'O': ('TAA', 'TGA', 'TAG'),\n",
    "    'H': ('CAT', 'CAC'),\n",
    "    'Q': ('CAA', 'CAG'),\n",
    "    'N': ('AAT', 'AAC'),\n",
    "    'K': ('AAA', 'AAG'),\n",
    "    'D': ('GAT', 'GAC'),\n",
    "    'E': ('GAA', 'GAG'),\n",
    "    'C': ('TGT', 'TGC'),\n",
    "    'W': ('TGG', ),\n",
    "    'R': ('CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'),\n",
    "    'G': ('GGT', 'GGC', 'GGA', 'GGG')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za svaku sekvencu brojimo koliko sadrži kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_codons(seq):\n",
    "    seq = seq[14]\n",
    "    \n",
    "    codon_counts = {a: 0 for a in standard_codon_table.keys()}\n",
    "    \n",
    "    for i in range(0, len(seq) - 2, 3):\n",
    "        codon = seq[i:i+3]\n",
    "        codon_counts[codon] += 1\n",
    "    \n",
    "    return codon_counts\n",
    "\n",
    "codon_counts = df[[14]].apply(count_codons, axis=1, result_type='expand').to_dict('list')\n",
    "codon_counts = {key: np.array(val, dtype='float64') for key, val in codon_counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za prebrojavanje amino-kiselina u prevedenim sekvencama, nećemo eksplicitno prevoditi sekvence i brojati.\n",
    "Iskoristićemo činjenicu da smo već izbrojali kodone u kodirajućim sekvencama.\n",
    "Sada ostaje da za svaku amino-kiselinu saberemo broj kodona koji ih kodiraju, za svaku sekvencu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = df.shape[0]\n",
    "\n",
    "amino_counts = {a: np.zeros(length) for a in inverse_codon_table.keys()}\n",
    "\n",
    "for amino, codons in inverse_codon_table.items():\n",
    "    for codon in codons:\n",
    "        amino_counts[amino] += codon_counts[codon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neka se kodon *X* pojavljuje *x* puta u nekoj sekvenci i kodira amino-kiselinu *Y*.\n",
    "U prevedenoj sekvenci, nakon transkripcije i translacije, amino-kiselina *Y* se pojavljuje *y* puta.\n",
    "Vrednost\n",
    "$$\n",
    "f(X) = \\frac{x}{y}\n",
    "$$\n",
    "predstavlja upotrebu kodona *X*.\n",
    "\n",
    "Postoje sekvence koje ne kodiraju sve amino-kiseline, što prilikom primene formule dovodi do deljenja nulom i dodele *NaN* vrednosti.\n",
    "Zamenićemo *NaN* vrednosti nulom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for codon in standard_codon_table.keys():\n",
    "    codon_counts[codon] /= amino_counts[standard_codon_table[codon]]\n",
    "    np.nan_to_num(codon_counts[codon], copy=False, nan=0, posinf=0, neginf=0) # ako delimo nulom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Završna priprema podataka i podela na skupove\n",
    "\n",
    "Rečnik sa vrednostima upotrebe kodona prevodimo u pogodniji format za rad sa tabelarnim podacima.\n",
    "Odbacujemo podatke o upotrebi stop kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(codon_counts)\n",
    "X.drop(['TAA', 'TGA', 'TAG', 'ATG'], axis=1, inplace=True)\n",
    "\n",
    "y = df[12]\n",
    "y.name = 'Protein'\n",
    "\n",
    "df = X.join(y, validate='one_to_one')\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "# df.to_csv('proteini_ucestalost_kodona.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pravimo enkoder koji kateogričkim ciljnim podacima dodeljuje celobrojne vrednosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "_ = enc.fit(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = LabelBinarizer()\n",
    "_ = ohe.fit(y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konačno, delimo podatke na podatke za test i trening skupove.\n",
    "Test skup će se sadržati 20% podataka, a ostatak će sadržati trening skup.\n",
    "Pravimo stratifikovanu podelu, kako bi sve klase bile jednako zastupljene u test i trening skupu.\n",
    "Dalje u analizi ćemo se fokusirati na trening skup.\n",
    "Test skup ćemo koristiti isključivo za proveru modela.\n",
    "U svim ostalim situacijama ponašamo se kao da test skup ne postoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small training data sample that will be used for certain visualization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = X_train.join(y_train, validate='one_to_one').groupby(['Protein']).sample(8, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_sample = train_sample.drop(['Protein'], axis=1)\n",
    "y_train_sample = train_sample['Protein']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long form of the small sampled training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_sample.shape[0] * (train_sample.shape[1] - 1)\n",
    "\n",
    "train_sample_long = {\n",
    "    'index': np.empty(shape, np.int32),\n",
    "    'codon': [None for _ in range(shape)],\n",
    "    'usage': np.empty(shape, np.float64),\n",
    "    'protein': [None for _ in range(shape)]\n",
    "}\n",
    "\n",
    "j = 0\n",
    "for i, s in X_train_sample.iterrows():\n",
    "    for codon, freq in s.items():\n",
    "        train_sample_long['index'][j] = i\n",
    "        train_sample_long['codon'][j] = codon\n",
    "        train_sample_long['usage'][j] = freq\n",
    "        train_sample_long['protein'][j] = y_train_sample.iloc[i]\n",
    "        j += 1\n",
    "\n",
    "train_sample_long = pd.DataFrame(train_sample_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizacija i upoznavanje sa podacima\n",
    "\n",
    "Neuravnoteženost klasa je veoma izražena.\n",
    "Najviše su zastupljene klase ORF1ab i ORF1a, kojima pripada oko $79\\%$ instanci.\n",
    "Više od $95\\%$ instanci predstavlja pet najzastupljenijih, od ukupno dvanaest klasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x=proteins.index,\n",
    "             y=proteins[:],\n",
    "             labels={'x': 'proteins',\n",
    "                     'y': 'samples'},\n",
    "             text_auto=True,\n",
    "             title='Class Balance',\n",
    "             width=1394,\n",
    "             height=450)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\chi ^2$ stats for target and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_2, p_v = chi2(X_train, y_train)\n",
    "\n",
    "ftc = pd.DataFrame({'chi2': c_2, 'p_value': p_v, 'codon': X_train.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(ftc,\n",
    "             x='codon',\n",
    "             y=['chi2', 'p_value'],\n",
    "             labels={'x': 'codons',\n",
    "                     'y': 'value'},\n",
    "             text_auto=True,\n",
    "             color_continuous_scale= px.colors.sequential.Jet,\n",
    "             title='Chi-squared stats between features and class',\n",
    "             width=1394,\n",
    "             height=450)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Coordinates\n",
    "\n",
    "Certainly this is an interesting looking plot.\n",
    "Its usefulness leaves some doubts, though.\n",
    "Difficult to see the forrest from the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.parallel_coordinates(X_train_sample,\n",
    "                              color=enc.transform(y_train_sample),\n",
    "                              color_continuous_scale=px.colors.sequential.Jet,\n",
    "                              title='Parallel Coordinates',\n",
    "                              width=1394,\n",
    "                              height=450)\n",
    "\n",
    "fig.update_layout(\n",
    "    coloraxis_colorbar={\n",
    "        'title': 'Protein',\n",
    "        'tickvals': np.array(range(12)),\n",
    "        'ticktext': [\n",
    "            a.split(' ')[0] for a in enc.inverse_transform(\n",
    "                np.array(range(12))\n",
    "        )],\n",
    "        'tickmode': 'array'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Chart\n",
    "\n",
    "The same thing like parallel coordinates, but a bit different.\n",
    "Abstract art.\n",
    "It appears that each class has different distribution and slightly different distinguishing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line_polar(train_sample_long,\n",
    "                    r='usage',\n",
    "                    theta='codon',\n",
    "                    color='protein',\n",
    "                    line_close=True,\n",
    "                    line_group='index',\n",
    "                    color_discrete_sequence=px.colors.sequential.Jet,\n",
    "                    range_r=[0, 1],\n",
    "                    title='Radar Chart',\n",
    "                    width=1394,\n",
    "                    height=450,\n",
    "                    render_mode='webgl')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n",
    "Stohastičko umetanje suseda sa t-raspodelim, kraće t-SNE, je nelinearni algoritam za dimenzionu redukciju.\n",
    "Važna osobina algoritma je da čuva relativna rastojanja, tako da slične podatke sa velikom verovatnoćom projektuje u tačke koje se nalaze međusobno blizu, a različite podatke daleko.\n",
    "Na žalost, zbog svoje stohastičke prirode, ovaj algoritam je pogodan samo za vizualizaciju podataka.\n",
    "\n",
    "Preporučeno je da za parametar *perplexity* biramo vrednosti između 5 i 50.\n",
    "Manje vrednosti previše naglašavaju lokalne strukture u podacima, dok veće vrednosti naglašavaju globalne strukture.\n",
    "Pored toga, da bi algoritam konvergirao, neophodno je da dozvolimo veliki broj iteracija.\n",
    "Zbog visoke dimenzionalnosti podataka biramo *Menhetn* rastojanje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2,\n",
    "            perplexity=48,\n",
    "            exaggeration=4,\n",
    "            n_iter=8192,\n",
    "            early_exaggeration_iter=1024,\n",
    "            n_jobs=-1, metric='manhattan',\n",
    "            learning_rate='auto',\n",
    "            initialization='random',\n",
    "            random_state=seed)\n",
    "\n",
    "X_train_tsne = tsne.fit(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klase se izdvajaju bez preklapanja, što je ohrabrujući rezultat i obećava dobru klasifikaciju."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x=X_train_tsne[:, 0],\n",
    "                 y=X_train_tsne[:, 1],\n",
    "                 color=y_train,\n",
    "                 color_continuous_scale=px.colors.sequential.Jet,\n",
    "                 labels={'x': '', 'y': ''},\n",
    "                 title='t-SNE',\n",
    "                 width=1394,\n",
    "                 height=450,\n",
    "                 render_mode='webgl')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treniranje i evaluacija modela\n",
    "\n",
    "Za izbor modela koristićemo unakrsnu proveru sa iscrpnom pretragom.\n",
    "\n",
    "Za sve algoritme, u unakrsnoj proveri ćemo koristiti metriku balansirane tačnosti.\n",
    "\n",
    "Za evaluaciju modela na trening i test skupovima posmatraćemo izvaštaj sa merama preciznosti, odziva i f1 merom, normalizovane matrice konfuzije i važnost atributa za cele skupove i za pojedinačne klase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_labels = proteins.index\n",
    "labels2display = np.array([a.split(' ', 1)[0] for a in protein_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_adapter = ExponentialAdapter(initial_value=c_prob,\n",
    "                                      end_value=m_prob,\n",
    "                                      adaptive_rate=a_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossover_adapter = ExponentialAdapter(initial_value=m_prob,\n",
    "                                       end_value=c_prob,\n",
    "                                       adaptive_rate=a_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_condition = DeltaThreshold(threshold=t_stop,\n",
    "                                    generations=stop,\n",
    "                                    metric='fitness_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss',\n",
    "                               min_delta=t_stop,\n",
    "                               patience=stop,\n",
    "                               start_from_epoch=start,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_generator = RandomHoldoutSplit(valid_size=0.2,\n",
    "                                                random_seed=seed,\n",
    "                                                stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_precision_recall(clf, X, y_true, title):\n",
    "    y_scores = clf.predict_proba(X)\n",
    "    y_onehot = pd.DataFrame(ohe.transform(y_true), columns=ohe.classes_)\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_shape(\n",
    "        type='line',\n",
    "        line={'dash': 'dash'},\n",
    "        x0=0,\n",
    "        x1=1,\n",
    "        y0=0,\n",
    "        y1=1\n",
    "    )\n",
    "    \n",
    "    for i in range(y_scores.shape[1]):\n",
    "        y_true = y_onehot.iloc[:, i]\n",
    "        y_score = y_scores[:, i]\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_score)\n",
    "        ap_score = average_precision_score(y_true, y_score)\n",
    "\n",
    "        name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "        fig.add_trace(\n",
    "            go.Scattergl(x=recall,\n",
    "                         y=precision,\n",
    "                         name=name,\n",
    "                         mode='lines')\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title='Recall',\n",
    "        yaxis_title='Precision',\n",
    "        yaxis={'scaleanchor': 'x',\n",
    "               'scaleratio': 1},\n",
    "        xaxis={'constrain': 'domain'},\n",
    "        width=1394,\n",
    "        height=450\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(confusion_matrix, display_labels, title):\n",
    "    fig = px.imshow(confusion_matrix.round(2),\n",
    "                    labels= {'x': 'Predicted value',\n",
    "                             'y': 'Real value'},\n",
    "                    x=display_labels,\n",
    "                    y=display_labels,\n",
    "                    title=title,\n",
    "                    aspect='auto',\n",
    "                    text_auto=True,\n",
    "                    color_continuous_scale=px.colors.sequential.Plasma,\n",
    "                    width=1394,\n",
    "                    height=450)\n",
    "    \n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_best_parameters(estimators):\n",
    "    print(', '.join([f'{a}: {b}' for a, b in estimators.best_params_.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Komplementarni naivni Bajesov algoritam\n",
    "\n",
    "Komplementarna varijacija algoritma računa verovatnoću da instanca ne pripada klasi i dodeljuje je onoj klasi sa najmanjom izračunatom verovatnoćom nepripadnosti.\n",
    "\n",
    "U *scikit-learn* implementaciji je ugrađen i algoriam za aditivno uglađivanje podataka koji prima *alpha* parametar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': Continuous(1e-3, 1e3, random_state=seed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(ComplementNB(),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametri najboljeg modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za trening skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za trening skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for ComplementNB - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for ComplementNB - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za test skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za test skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for ComplementNB - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for ComplementNB - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for ComplementNB',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for ComplementNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for ComplementNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion': Categorical(['gini', 'entropy'], random_state=seed),\n",
    "          'max_depth': Integer(4, 32, random_state=seed),\n",
    "          'min_samples_split': Integer(128, 256, random_state=seed),\n",
    "          'min_samples_leaf': Integer(32, 64, random_state=seed),\n",
    "          'min_impurity_decrease': Continuous(0, 1, random_state=seed),\n",
    "          'ccp_alpha': Continuous(0, 2, random_state=seed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(DecisionTreeClassifier(class_weight='balanced',\n",
    "                                        random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            enc.transform(y_train),\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametri najboljeg modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, enc.inverse_transform(clf.predict(X_train))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for DecisionTreeClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for DecisionTreeClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, enc.inverse_transform(clf.predict(X_test))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for DecisionTreeClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for DecisionTreeClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafički prikaz drveta odlučivanja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model = dtreeviz.model(clf.best_estimator_,\n",
    "                           X_train=X_train.values,\n",
    "                           y_train=enc.transform(y_train),\n",
    "                           feature_names=X_train.columns.to_list(),\n",
    "                           target_name='Proteins',\n",
    "                           class_names=list(enc.inverse_transform(clf.best_estimator_.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model.view(scale=0.75,\n",
    "               leaftype='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model.ctree_leaf_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model.ctree_feature_space(features=['TTC', 'TGC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for DecisionTreeClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nasumična šuma\n",
    "\n",
    "Unakrsnom proverom ćemo testirati modele sa različitim brojem klasifikatora i najvećim dozvoljenim brojevima atributa i instanci u uzorcima.\n",
    "Pustićemo da se stabla preprilagode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': Integer(32, 256, random_state=seed),\n",
    "           'criterion': Categorical(['gini', 'entropy'], random_state=seed),\n",
    "           'max_features': Continuous(0, 1, random_state=seed),\n",
    "           'max_samples': Continuous(0, 1, random_state=seed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(RandomForestClassifier(n_jobs=-1,\n",
    "                                        random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=2,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametri najboljeg modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for RandomForestClassifier - training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for RandomForestClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for RandomForestClassifier - test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for RandomForestClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for RandomForestClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': Integer(4, 96, random_state=seed),\n",
    "           'max_depth': Integer(1, 4, random_state=seed),\n",
    "           'grow_policy': Categorical([0, 1], random_state=seed),\n",
    "           'gamma': Continuous(0, 1, random_state=seed),\n",
    "           'learning_rate': Continuous(0, 1, random_state=seed),\n",
    "           'objective': Categorical(['reg:linear',\n",
    "                                     'reg:logistic',\n",
    "                                     'multi:softmax',\n",
    "                                     'multi:softprob'], random_state=seed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(XGBClassifier(nthread=-1,\n",
    "                               random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=2,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            enc.transform(y_train),\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametri najboljeg modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, enc.inverse_transform(clf.predict(X_train))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za trening skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for XGBClassifier - training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for XGBClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izveštaj za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, enc.inverse_transform(clf.predict(X_test))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrica konfuzije za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for XGBClassifier - training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for XGBClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for XGBClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for XGBClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for XGBClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine\n",
    "\n",
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': Continuous(0, 1e3, random_state=seed),\n",
    "          'intercept_scaling': Continuous(0, 1e3, random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(LinearSVC(dual='auto',\n",
    "                           class_weight='balanced',\n",
    "                           tol=t_stop,\n",
    "                           max_iter=maxiter,\n",
    "                           random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability calibration with isotonic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CalibratedClassifierCV(clf.best_estimator_,\n",
    "                             method='isotonic',\n",
    "                             cv='prefit')\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, clf.predict(X_train)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for LinearSVC - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for LinearSVC - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for LinearSVC - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for LinearSVC - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for LinearSVC',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for LinearSVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "I found a wrapper library *scikeras* that gives *tensorflow*/*keras* interface like *scikit-learn* API.\n",
    "It turned out to be a bit of disappointment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layer_dim,\n",
    "              dropout_rate,\n",
    "              activation_function,\n",
    "              meta):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(meta['n_features_in_'],\n",
    "                    input_shape=meta['X_shape_'][1:],\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(meta['n_classes_'],\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the cross-valudation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'optimizer': ['adam',\n",
    "                        'rmsprop'],\n",
    "          'loss': ['categorical_hinge',\n",
    "                   'categorical_crossentropy'],\n",
    "          'activation_function': ['relu',\n",
    "                                  'sigmoid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KerasClassifier* did not work well with the genetic algorithm, and it does not appear to be working that well with the grid search either.\n",
    "The wrapper appears to be broken, as it throws warnings both left and right.\n",
    "It also fails to report the score.\n",
    "I have decided to keep it because I like the idea of having a decent neural network classifier with *scikit-learn* interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(KerasClassifier(get_model,\n",
    "                                   dropout_rate=0.2,\n",
    "                                   hidden_layer_dim=31,\n",
    "                                   activation_function='relu',\n",
    "                                   # class_weight='balanced', # causes warnings\n",
    "                                   metrics=AUC(name='prc', curve='PR'),\n",
    "                                   epochs=maxiter,\n",
    "                                   callbacks=early_stopping,\n",
    "                                   validation_split=0.2,\n",
    "                                   batch_size=-1,\n",
    "                                   verbose=0,\n",
    "                                   random_state=seed),\n",
    "                   param_grid=params,\n",
    "                   scoring=lambda a, b: balanced_accuracy_score(ohe.inverse_transform(a),\n",
    "                                                                ohe.inverse_transform(b)),\n",
    "                   cv=cross_validation_generator,\n",
    "                   n_jobs=2)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            ohe.transform(y_train),\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, ohe.inverse_transform(clf.predict(X_train))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for KerasClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precission-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                X_train,\n",
    "                y_train,\n",
    "                'Precision-recall curves for KerasClassifier - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, ohe.inverse_transform(clf.predict(X_test))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for KerasClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                X_test,\n",
    "                y_test,\n",
    "                'Precision-recall curves for KerasClassifier - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(ohe.inverse_transform(a.predict(b))),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for KerasClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            title='Variable importance measures for KerasClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            title='Variable importance measures for KerasClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximate k-Nearest Neighbors\n",
    "\n",
    "A more efficient implementation of k-Nearest Neighbors search than the one given in *scikit-learn*.\n",
    "Initially, I tried various implementations based on HSNW search, but I could not find a library that builds indexer deterministically.\n",
    "*Annoy* indexer might be a bit slower, but at least every time I retrain the classifier, with the same set of parameters, I get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnoyKNN:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 weighted=False,\n",
    "                 metric='manhattan',\n",
    "                 k=5,\n",
    "                 n_trees=128,\n",
    "                 n_jobs=1,\n",
    "                 random_state=None):\n",
    "        assert isinstance(weighted, bool), 'weighted has to be bool'\n",
    "        assert metric in ('angular',\n",
    "                          'euclidean',\n",
    "                          'manhattan',\n",
    "                          'hamming',\n",
    "                          'dot'), 'metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"'\n",
    "        assert isinstance(k, int), 'k has to be int'\n",
    "        assert isinstance(n_trees, int), 'n_trees has to be int'\n",
    "        assert isinstance(n_jobs, int), 'n_jobs has to be int'\n",
    "        assert isinstance(random_state, (int, type(None))), 'random_state has to be int or None'\n",
    "        \n",
    "        self.index = None\n",
    "        self.X = pd.DataFrame()\n",
    "        self.y = None\n",
    "        self.classes_ = None\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.n_trees = n_trees\n",
    "        self.n_jobs = n_jobs\n",
    "        self.weighted = weighted\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __sklearn_clone__(self):\n",
    "        clone = AnnoyKNN(self.weighted,\n",
    "                         self.metric,\n",
    "                         self.k,\n",
    "                         self.n_trees,\n",
    "                         self.n_jobs,\n",
    "                         self.random_state)\n",
    "        clone.X = self.X\n",
    "        clone.index = self.index\n",
    "        \n",
    "        return clone\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'index': self.index,\n",
    "                'y': self.y,\n",
    "                'k': self.k,\n",
    "                'classes_': self.classes_,\n",
    "                'metric': self.metric,\n",
    "                'n_trees': self.n_trees,\n",
    "                'n_jobs': self.n_jobs,\n",
    "                'weighted': self.weighted,\n",
    "                'random_state': self.random_state}\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for key, val in params.items():\n",
    "            if key in ('metric',\n",
    "                       'n_trees',\n",
    "                       'random_state'):\n",
    "                self.index = None\n",
    "            self.__dict__[key] = val\n",
    "\n",
    "        assert isinstance(self.weighted, bool), 'weighted has to be bool'\n",
    "        assert self.metric in ('angular',\n",
    "                               'euclidean',\n",
    "                               'manhattan',\n",
    "                               'hamming',\n",
    "                               'dot'), 'metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"'\n",
    "        assert isinstance(self.k, int), 'k has to be int'\n",
    "        assert isinstance(self.n_trees, int), 'n_trees has to be int'\n",
    "        assert isinstance(self.n_jobs, int), 'n_jobs has to be int'\n",
    "        assert isinstance(self.random_state, (int, type(None))), 'random_state has to be int or None'\n",
    "        assert isinstance(self.X, pd.DataFrame), 'X has to be pandas DataFrame object'\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        assert isinstance(X, pd.DataFrame), 'X has to be pandas DataFrame object'\n",
    "        if self.index is None or not X.equals(self.X):\n",
    "            self.X = X\n",
    "            \n",
    "            self.index = AnnoyIndex(X.shape[1], self.metric)\n",
    "            self.index.set_seed(self.random_state)\n",
    "            \n",
    "            for i, v in enumerate(X.to_numpy()):\n",
    "                self.index.add_item(i, v)\n",
    "            self.index.build(self.n_trees, self.n_jobs)\n",
    "            \n",
    "        assert isinstance(y, pd.Series), 'y has to be pandas Series object'\n",
    "        self.y = y.to_numpy()\n",
    "        self.classes_ = np.unique(self.y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def score(self. X, y, sample_weight=None):\n",
    "        assert self.index is not None, 'first to fit the model you have'\n",
    "        assert isinstance(X, pd.DataFrame), 'X has to be pandas DataFrame object'\n",
    "        assert isinstance(y, (pd.Series, np.array)), 'y has to be pandas Series or numpy array object'\n",
    "        y_true = y\n",
    "        y_pred = self.predict(X)\n",
    "        \n",
    "        return balanced_accuracy_score(y_true,\n",
    "                                       y_pred,\n",
    "                                       sample_weight)\n",
    "\n",
    "    def __get_weighted_votes(self, X):\n",
    "        indices = np.empty((X.shape[0], self.k),\n",
    "                           dtype=np.int32)\n",
    "        distances = np.empty((X.shape[0], self.k),\n",
    "                             dtype=np.float64)\n",
    "        \n",
    "        # Annoy is annoying for not having batch query ...\n",
    "        for i, v in enumerate(X.to_numpy()):\n",
    "            tmp_i, tmp_d = self.index.get_nns_by_vector(v,\n",
    "                                                        self.k,\n",
    "                                                        include_distances=self.weighted)\n",
    "            indices[i] = np.array(tmp_i,\n",
    "                                  dtype=np.int32)\n",
    "            distances[i] = np.array(tmp_d,\n",
    "                                    dtype=np.float64)\n",
    "        \n",
    "        vote = self.y[indices]\n",
    "        weight = np.reciprocal(distances,\n",
    "                               where=distances!=0,\n",
    "                               out=np.zeros_like(distances))\n",
    "        weighted_votes = [(vote[a], weight[a]) for a in range(indices.shape[0])]\n",
    "        \n",
    "        return weighted_votes\n",
    "    \n",
    "    def __get_unweighted_votes(self, X):        \n",
    "        indices = np.empty((X.shape[0], self.k),\n",
    "                           dtype=np.int32)\n",
    "        \n",
    "        # Annoy is annoying for not having batch query ...\n",
    "        for i, v in enumerate(X.to_numpy()):\n",
    "            tmp_i = self.index.get_nns_by_vector(v,\n",
    "                                                 self.k,\n",
    "                                                 include_distances=self.weighted)\n",
    "            indices[i] = np.array(tmp_i,\n",
    "                                  dtype=np.int32)\n",
    "        \n",
    "        unweighted_votes = self.y[indices]\n",
    "        \n",
    "        return unweighted_votes\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert isinstance(X, pd.DataFrame), 'X has to be pandas DataFrame object'\n",
    "        predictions = None\n",
    "        \n",
    "        if self.weighted:\n",
    "            votes = self.__get_weighted_votes(X)\n",
    "            \n",
    "            predictions = np.array([np.argmax(np.bincount(a,\n",
    "                                                          weights=b)) for a, b in votes],\n",
    "                                   dtype=np.int32)\n",
    "        else:\n",
    "            votes = self.__get_unweighted_votes(X)\n",
    "            \n",
    "            predictions = np.array([np.argmax(np.bincount(a)) for a in votes],\n",
    "                                   dtype=np.int32)\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        assert isinstance(X, pd.DataFrame), 'X has to be pandas DataFrame object'\n",
    "        probabilities = None\n",
    "        \n",
    "        if self.weighted:\n",
    "            votes = self.__get_weighted_votes(X)\n",
    "            \n",
    "            numerator = np.array([np.bincount(a,\n",
    "                                              weights=b,\n",
    "                                              minlength=self.classes_.shape[0]) for a, b in votes])\n",
    "            denominator = np.array([a.sum() for a in numerator])\n",
    "            probabilities = np.array([a / b for a, b in zip(numerator, denominator)])\n",
    "        else:\n",
    "            votes = self.__get_unweighted_votes(X)\n",
    "\n",
    "            numerator = np.array([np.bincount(a,\n",
    "                                              minlength=self.classes_.shape[0]) for a in votes])\n",
    "            denominator = self.k\n",
    "            probabilities = numerator / denominator\n",
    "            \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'k': [5, 13, 23, 31],\n",
    "          'weighted': [True, False]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve the best performance, since the search space is small, instead of the genetic algorithm, simple grid search will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(AnnoyKNN(n_jobs=-1,\n",
    "                            random_state=seed),\n",
    "                   param_grid=params,\n",
    "                   scoring='balanced_accuracy',\n",
    "                   cv=cross_validation_generator)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            pd.Series(enc.transform(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_train, enc.inverse_transform(clf.predict(X_train))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for AnnoyKNN - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_train,\n",
    "                         y_train,\n",
    "                         'Precision-recall curves for AnnoyKNN - training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = y_test, enc.inverse_transform(clf.predict(X_test))\n",
    "\n",
    "print(classification_report(y_true,\n",
    "                            y_pred,\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,\n",
    "                      y_pred,\n",
    "                      normalize='true',\n",
    "                      labels=protein_labels)\n",
    "\n",
    "display_confusion_matrix(cm,\n",
    "                         display_labels=labels2display,\n",
    "                         title='Confusion matrix for AnnoyKNN - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_precision_recall(clf,\n",
    "                         X_test,\n",
    "                         y_test,\n",
    "                         'Precision-recall curves for AnnoyKNN - test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances.\n",
    "Since SHAP library dislikes my implementation of AnnoyKNN, and since it's so well documented that it makes debugging impossible, instead of using SHAP values, simple permutation importances will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_test,\n",
    "                         enc.transform(y_test),\n",
    "                         precalculate=False,\n",
    "                         label='Variable importance measures for AnnoyKNN',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(keep_raw_permutations=False,\n",
    "                               random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_vars=n_features,\n",
    "            title='Variable importance measures for AnnoyKNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After loading the data, features containing coding sequences and protein types have been extracted.\n",
    "Then, we cleaned up the data by dropping the sequences with inappropriate number of nucleotides, with ambiguities, or belong to the classes represented by too few instances for reliable generalization.\n",
    "\n",
    "The preparation phase has been completed by calculating codon usage frequencies and splitting the data into train and test sets.\n",
    "A couple of other utilities have been prepared, before moving on to visualization phase.\n",
    "\n",
    "During the visualization phase, we first looked at some general statistics.\n",
    "That is, distribution of instances in different classes and $\\chi ^2$ test to determine feature importances.\n",
    "Then we looked at parallel coordinates and radar chart of a sampled data, and finally we looked at *t-SNE* projection of the training dataset.\n",
    "Then, we moved on to classification.\n",
    "\n",
    "It appears that the data is linearly separable, as the linear-like classifiers such as *LinearSVC* and *DecisionTreeClassifier* achieved excellent results.\n",
    "Even my custom built *AnnoyKNN* classifier, based on *Annoy* indexer, favored fewer neighbors and ignored distances, which implies that it prefers more linear separation of the data.\n",
    "\n",
    "*ComplementaryNB* struggled with imbalanced data.\n",
    "It simply failed to recognize the underrepresented classes.\n",
    "\n",
    "The best results have been achieved with ensemble methods based on decision trees.\n",
    "That doesn't come as a surprise, as even a single decision tree has achieved significant result.\n",
    "\n",
    "This version of *KerasClassifier* appears to be broken.\n",
    "In conjunction with *GASearchCV* it fails to report classification score, which is necessary for triggering early stopping callback.\n",
    "Instead it returned NaN values.\n",
    "When used with ordinary *GridSearchCV* it triggerd a lot of warnings for variables that are even not accessible from *scikeras* API.\n",
    "Finally, the model it generated is practically useless.\n",
    "\n",
    "This version of *GASearchCV* does not parallelize at all, despite having n_jobs parameter.\n",
    "If it has to evaluate *n* models during an iteration, and it has *n* cores available, I would expect that it would train each model in a separate process.\n",
    "Instead, the models are trained one at a time, which is a serious flaw of this implementation.\n",
    "\n",
    "Overall, we trained seven models, out of which five have demonstrated excellent performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
