{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Perform classification of protein types based on codon usage in SARS-CoV2.\n",
    "\n",
    "- use the [data](alas.matf.bg.ac.rs) containing coding sequences and protein types, prepared from [NCBI Virus](https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/virus?SeqType_s=Nucleotide&VirusLineage_ss=SARS-CoV-2,%20taxid:2697049).\n",
    "\n",
    "- use standard codon table from [The Genetic Codes](https://www.ncbi.nlm.nih.gov/Taxonomy/Utils/wprintgc.cgi).\n",
    "Za SARS2 koristiti standardni kod (transl_table=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dtreeviz\n",
    "import dalex as dx\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve as prec_rec_crve, balanced_accuracy_score, classification_report\n",
    "\n",
    "from mlxtend.evaluate import confusion_matrix as conf_matrx, RandomHoldoutSplit\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "from openTSNE import TSNE\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Recall\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn_genetic import ExponentialAdapter, GASearchCV\n",
    "from sklearn_genetic.callbacks import DeltaThreshold\n",
    "from sklearn_genetic.space import Categorical, Integer, Continuous\n",
    "\n",
    "from yellowbrick.target import class_balance\n",
    "from yellowbrick.target.feature_correlation import feature_correlation\n",
    "from yellowbrick.features.pcoords import parallel_coordinates\n",
    "from yellowbrick.features.radviz import radviz\n",
    "from yellowbrick.classifier import confusion_matrix, precision_recall_curve\n",
    "from yellowbrick.model_selection import feature_importances\n",
    "from yellowbrick.contrib.wrapper import classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
    "\n",
    "stop = 5\n",
    "start = 7\n",
    "\n",
    "tous = 11\n",
    "pops = 31\n",
    "seed = 196883\n",
    "\n",
    "sample = 4224\n",
    "maxiter = np.iinfo(np.int32).max\n",
    "\n",
    "t_stop = 1e-4\n",
    "t_sample = 0.2\n",
    "\n",
    "a_rate = 0.1\n",
    "m_prob = 0.2\n",
    "c_prob = 0.8\n",
    "\n",
    "n_features = 7\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Priprema podataka\n",
    "\n",
    "Učitavamo podatke sa jedinstvenim kodirajućim sekvencama proteina SARS-CoV-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('samo_jedinstvene_kodirajuce_sekvence.csv', header=None, on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Izdvajamo kolonu sa kodirajućim sekvencama i kolonu sa oznakama tipova proteina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[14, 12]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Čišćenje podataka\n",
    "\n",
    "Proveravamo da li su kodirajuće sekvence odgovarajuće dužine.\n",
    "One koje nisu, odbacujemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = np.array([len(a) for a in df[14]])\n",
    "valid = (length > 8) & (length % 3 == 0)\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proveravamo da li se kodirajuće sekvence sastoje samo od slova A, T, C i G.\n",
    "Sekvence koje ne ispunjavaju ovaj uslov odbacujemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = df[14].map(lambda a: set(a).issubset(set('ATCG')))\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proveravamo koliko instanci imamo u svakoj klasi.\n",
    "Odnosno koliko sekvenci imamo za svaki tip proteina.\n",
    "Klase koje sadrže 64 instanci i manje odbacujemo zajedno sa instancom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = df.groupby([12])[12].count()\n",
    "valid = np.array([proteins[a] for a in df[12]]) > 64\n",
    "\n",
    "df = df[valid]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon čišćenja podataka, od jedinstvenih 889737 kodirajućih ostalo nam je 869858 instanci.\n",
    "Ukupno 19879 instanci je odbačeno kao nevalidno, odnosno oko $2.23\\%$ skupa jedinstvenih kodirajućih sekvenci.\n",
    "\n",
    "### Izračunavanje upotrebe kodona\n",
    "\n",
    "Računamo koliko često neki kodon kodira svoju amino-kiselinu u svakoj kodirajućoj sekvenci.\n",
    "\n",
    "Potrebna nam je standardna tabela kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_codon_table = {\n",
    "    'TTT': 'F', 'TCT': 'S', 'TAT': 'Y', 'TGT': 'C',\n",
    "    'TTC': 'F', 'TCC': 'S', 'TAC': 'Y', 'TGC': 'C',\n",
    "    'TTA': 'L', 'TCA': 'S', 'TAA': 'O', 'TGA': 'O',\n",
    "    'TTG': 'L', 'TCG': 'S', 'TAG': 'O', 'TGG': 'W',\n",
    "\n",
    "    'CTT': 'L', 'CCT': 'P', 'CAT': 'H', 'CGT': 'R',\n",
    "    'CTC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R',\n",
    "    'CTA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R',\n",
    "    'CTG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R',\n",
    "\n",
    "    'ATT': 'I', 'ACT': 'T', 'AAT': 'N', 'AGT': 'S',\n",
    "    'ATC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S',\n",
    "    'ATA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R',\n",
    "    'ATG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R',\n",
    "\n",
    "    'GTT': 'V', 'GCT': 'A', 'GAT': 'D', 'GGT': 'G',\n",
    "    'GTC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G',\n",
    "    'GTA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G',\n",
    "    'GTG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potrebna nam je i inverzna tabela kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_codon_table = {\n",
    "    'F': ('TTT', 'TTC'),\n",
    "    'L': ('CTT', 'CTC', 'CTA', 'CTG', 'TTA', 'TTG'),\n",
    "    'I': ('ATT', 'ATC', 'ATA'),\n",
    "    'M': ('ATG', ),\n",
    "    'V': ('GTT', 'GTC', 'GTA', 'GTG'),\n",
    "    'S': ('TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'),\n",
    "    'P': ('CCT', 'CCC', 'CCA', 'CCG'),\n",
    "    'T': ('ACT', 'ACC', 'ACA', 'ACG'),\n",
    "    'A': ('GCT', 'GCC', 'GCA', 'GCG'),\n",
    "    'Y': ('TAT', 'TAC'),\n",
    "    'O': ('TAA', 'TGA', 'TAG'),\n",
    "    'H': ('CAT', 'CAC'),\n",
    "    'Q': ('CAA', 'CAG'),\n",
    "    'N': ('AAT', 'AAC'),\n",
    "    'K': ('AAA', 'AAG'),\n",
    "    'D': ('GAT', 'GAC'),\n",
    "    'E': ('GAA', 'GAG'),\n",
    "    'C': ('TGT', 'TGC'),\n",
    "    'W': ('TGG', ),\n",
    "    'R': ('CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'),\n",
    "    'G': ('GGT', 'GGC', 'GGA', 'GGG')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za svaku sekvencu brojimo koliko sadrži kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_codons(seq):\n",
    "    seq = seq[14]\n",
    "    \n",
    "    codon_counts = {a: 0 for a in standard_codon_table.keys()}\n",
    "    \n",
    "    for i in range(0, len(seq) - 2, 3):\n",
    "        codon = seq[i:i+3]\n",
    "        codon_counts[codon] += 1\n",
    "    \n",
    "    return codon_counts\n",
    "\n",
    "codon_counts = df[[14]].apply(count_codons, axis=1, result_type='expand').to_dict('list')\n",
    "codon_counts = {key: np.array(val, dtype='float64') for key, val in codon_counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za prebrojavanje amino-kiselina u prevedenim sekvencama, nećemo eksplicitno prevoditi sekvence i brojati.\n",
    "Iskoristićemo činjenicu da smo već izbrojali kodone u kodirajućim sekvencama.\n",
    "Sada ostaje da za svaku amino-kiselinu saberemo broj kodona koji ih kodiraju, za svaku sekvencu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = df.shape[0]\n",
    "\n",
    "amino_counts = {a: np.zeros(length) for a in inverse_codon_table.keys()}\n",
    "\n",
    "for amino, codons in inverse_codon_table.items():\n",
    "    for codon in codons:\n",
    "        amino_counts[amino] += codon_counts[codon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neka se kodon *X* pojavljuje *x* puta u nekoj sekvenci i kodira amino-kiselinu *Y*.\n",
    "U prevedenoj sekvenci, nakon transkripcije i translacije, amino-kiselina *Y* se pojavljuje *y* puta.\n",
    "Vrednost\n",
    "$$\n",
    "f(X) = \\frac{x}{y}\n",
    "$$\n",
    "predstavlja upotrebu kodona *X*.\n",
    "\n",
    "Postoje sekvence koje ne kodiraju sve amino-kiseline, što prilikom primene formule dovodi do deljenja nulom i dodele *NaN* vrednosti.\n",
    "Zamenićemo *NaN* vrednosti nulom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for codon in standard_codon_table.keys():\n",
    "    codon_counts[codon] /= amino_counts[standard_codon_table[codon]]\n",
    "    np.nan_to_num(codon_counts[codon], copy=False, nan=0, posinf=0, neginf=0) # ako delimo nulom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Završna priprema podataka i podela na skupove\n",
    "\n",
    "Rečnik sa vrednostima upotrebe kodona prevodimo u pogodniji format za rad sa tabelarnim podacima.\n",
    "Odbacujemo podatke o upotrebi stop kodona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(codon_counts)\n",
    "X.drop(['TAA', 'TGA', 'TAG', 'ATG'], axis=1, inplace=True)\n",
    "\n",
    "y = df[12]\n",
    "y.name = 'Protein'\n",
    "\n",
    "df = X.join(y, validate='one_to_one')\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "# df.to_csv('proteini_ucestalost_kodona.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pravimo enkoder koji kateogričkim ciljnim podacima dodeljuje celobrojne vrednosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "_ = enc.fit(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = LabelBinarizer()\n",
    "_ = ohe.fit(y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konačno, delimo podatke na podatke za test i trening skupove.\n",
    "Test skup će se sadržati 20% podataka, a ostatak će sadržati trening skup.\n",
    "Pravimo stratifikovanu podelu, kako bi sve klase bile jednako zastupljene u test i trening skupu.\n",
    "Dalje u analizi ćemo se fokusirati na trening skup.\n",
    "Test skup ćemo koristiti isključivo za proveru modela.\n",
    "U svim ostalim situacijama ponašamo se kao da test skup ne postoji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small training data sample that will be used for certain visualization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = X_train.join(y_train, validate='one_to_one').groupby(['Protein']).sample(8, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "X_train_sample = train_sample.drop(['Protein'], axis=1)\n",
    "y_train_sample = train_sample['Protein']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long form of the small sampled training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = train_sample.shape[0] * (train_sample.shape[1] - 1)\n",
    "\n",
    "train_sample_long = {\n",
    "    'index': np.empty(shape, np.int32),\n",
    "    'codon': [None for _ in range(shape)],\n",
    "    'usage': np.empty(shape, np.float64),\n",
    "    'protein': [None for _ in range(shape)]\n",
    "}\n",
    "\n",
    "j = 0\n",
    "for i, s in X_train_sample.iterrows():\n",
    "    for codon, freq in s.items():\n",
    "        train_sample_long['index'][j] = i\n",
    "        train_sample_long['codon'][j] = codon\n",
    "        train_sample_long['usage'][j] = freq\n",
    "        train_sample_long['protein'][j] = y_train_sample.iloc[i]\n",
    "        j += 1\n",
    "\n",
    "train_sample_long = pd.DataFrame(train_sample_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data vizualization\n",
    "\n",
    "The classes are very unbalanced.\n",
    "About $79\\%$ instances belong to *ORF1ab* i *ORF1a*.\n",
    "More than $95\\%$ of instances are in five, out of total twelve classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = class_balance(y_train,\n",
    "                  labels=[a.split()[0] for a in enc.classes_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for target and features\n",
    "\n",
    "We will look at correlations between target variable and the features to see if there are any variables that stand out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = feature_correlation(X=X_train,\n",
    "                        y=y_train,\n",
    "                        method='mutual_info-classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Coordinates\n",
    "\n",
    "Certainly this is an interesting looking plot.\n",
    "Its usefulness leaves some doubts, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = parallel_coordinates(X=X_train_sample,\n",
    "                         y=y_train_sample,\n",
    "                         alpha=0.6,\n",
    "                         normalize='standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radar Chart\n",
    "\n",
    "Just like parallel coordinates, but a bit different.\n",
    "Abstract art.\n",
    "Although there are some overlappings, classes appear to be separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = radviz(X=X_train,\n",
    "       y=enc.transform(y_train),\n",
    "       classes=enc.classes_,\n",
    "       alpha=0.6,\n",
    "       colormap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n",
    "T-distributed stochastic neighbor embedding, shorter t-SNE, is nonlinear algorithm for dimensionality reduction.\n",
    "Due to its stochastic nature, this algorithm is suitable only for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2,\n",
    "            perplexity=48,\n",
    "            exaggeration=4,\n",
    "            n_iter=8192,\n",
    "            early_exaggeration_iter=1024,\n",
    "            n_jobs=-1, metric='manhattan',\n",
    "            learning_rate='auto',\n",
    "            initialization='random',\n",
    "            random_state=seed)\n",
    "\n",
    "X_train_tsne = tsne.fit(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes separate without overlapping, which is a good result, and promisses good classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "ax = sns.scatterplot(x=X_train_tsne[:, 0],\n",
    "                     y=X_train_tsne[:, 1],\n",
    "                     hue=y_train,\n",
    "                     palette='jet')\n",
    "# ax.set(xlabel='', ylabel='')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "For parameter tuning we will use cross-validation.\n",
    "For cross-validation *balanced accuracy* metric will be used.\n",
    "\n",
    "During the evaluation we will observe model performance on training and test datasets.\n",
    "Aside from classification report with metrics, we will look at confusion matrices and precision-recall curves.\n",
    "Finally, we will take a look at feature importances.\n",
    "\n",
    "First, let us write some utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_labels = enc.classes_\n",
    "labels2display = np.array([a.split(' ', 1)[0] for a in protein_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutation_adapter = ExponentialAdapter(initial_value=c_prob,\n",
    "                                      end_value=m_prob,\n",
    "                                      adaptive_rate=a_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossover_adapter = ExponentialAdapter(initial_value=m_prob,\n",
    "                                       end_value=c_prob,\n",
    "                                       adaptive_rate=a_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopping_condition = DeltaThreshold(threshold=t_stop,\n",
    "                                    generations=stop,\n",
    "                                    metric='fitness_max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='loss',\n",
    "                               min_delta=t_stop,\n",
    "                               patience=stop,\n",
    "                               start_from_epoch=start,\n",
    "                               restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation_generator = RandomHoldoutSplit(valid_size=0.2,\n",
    "                                                random_seed=seed,\n",
    "                                                stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_best_parameters(estimator):\n",
    "    print(', '.join([f'{a}: {b}' for a, b in estimator.best_params_.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement Naive Bayes Classifier\n",
    "\n",
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'alpha': Continuous(1e-3, 1e3, random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(ComplementNB(),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=clf.predict(X_train),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_train,\n",
    "                     y_train,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_train,\n",
    "                           y_train,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=clf.predict(X_test),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_test,\n",
    "                           y_test,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for ComplementNB',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for ComplementNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for ComplementNB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'criterion': Categorical(['gini', 'entropy'], random_state=seed),\n",
    "          'max_depth': Integer(4, 32, random_state=seed),\n",
    "          'min_samples_split': Integer(128, 256, random_state=seed),\n",
    "          'min_samples_leaf': Integer(32, 64, random_state=seed),\n",
    "          'min_impurity_decrease': Continuous(0, 1, random_state=seed),\n",
    "          'ccp_alpha': Continuous(0, 2, random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(DecisionTreeClassifier(class_weight='balanced',\n",
    "                                        random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            enc.transform(y_train),\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_train)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_train,\n",
    "                     enc.transform(y_train),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_train,\n",
    "                           y_train,\n",
    "                           encoder=enc,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_test)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_test,\n",
    "                     enc.transform(y_test),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_test,\n",
    "                           y_test,\n",
    "                           encoder=enc,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphical view of the decision tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model = dtreeviz.model(clf.best_estimator_,\n",
    "                           X_train=X_train.values,\n",
    "                           y_train=enc.transform(y_train),\n",
    "                           feature_names=X_train.columns.to_list(),\n",
    "                           target_name='Proteins',\n",
    "                           class_names=list(enc.inverse_transform(clf.best_estimator_.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model.view(scale=0.75,\n",
    "               leaftype='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for DecisionTreeClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Cross-validation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': Integer(32, 256, random_state=seed),\n",
    "           'criterion': Categorical(['gini', 'entropy'], random_state=seed),\n",
    "           'max_features': Continuous(0, 1, random_state=seed),\n",
    "           'max_samples': Continuous(0, 1, random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(RandomForestClassifier(n_jobs=-1,\n",
    "                                        random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=2,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=clf.predict(X_train),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_train,\n",
    "                     y_train,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_train,\n",
    "                           y_train,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=clf.predict(X_test),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(clf.best_estimator_,\n",
    "                           X_test,\n",
    "                           y_test,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for RandomForestClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for SVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting\n",
    "\n",
    "Cross-validation parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': Integer(4, 96, random_state=seed),\n",
    "           'max_depth': Integer(1, 4, random_state=seed),\n",
    "           'grow_policy': Categorical(['depthwise',\n",
    "                                       'lossguide'], random_state=seed),\n",
    "           'gamma': Continuous(0, 1, random_state=seed),\n",
    "           'learning_rate': Continuous(0, 1, random_state=seed),\n",
    "           'objective': Categorical(['reg:linear',\n",
    "                                     'reg:logistic',\n",
    "                                     'multi:softmax',\n",
    "                                     'multi:softprob'], random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(XGBClassifier(nthread=-1,\n",
    "                               random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=2,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            enc.transform(y_train),\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_train)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_train,\n",
    "                     enc.transform(y_train),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_train)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_train), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_test)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf.best_estimator_,\n",
    "                     X_test,\n",
    "                     enc.transform(y_test),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_test)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_test), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Važnost atributa za test skup podataka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for XGBClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for XGBClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for XGBClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vector Machine\n",
    "\n",
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': Continuous(0, 1e3, random_state=seed),\n",
    "          'intercept_scaling': Continuous(0, 1e3, random_state=seed)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GASearchCV(LinearSVC(dual='auto',\n",
    "                           class_weight='balanced',\n",
    "                           tol=t_stop,\n",
    "                           max_iter=maxiter,\n",
    "                           random_state=seed),\n",
    "                 param_grid=params,\n",
    "                 scoring='balanced_accuracy',\n",
    "                 population_size=pops,\n",
    "                 generations=maxiter,\n",
    "                 tournament_size=tous,\n",
    "                 elitism=True,\n",
    "                 crossover_probability=crossover_adapter,\n",
    "                 mutation_probability=mutation_adapter,\n",
    "                 cv=cross_validation_generator,\n",
    "                 algorithm='eaSimple',\n",
    "                 n_jobs=-1,\n",
    "                 verbose=False)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train,\n",
    "            callbacks=stopping_condition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability calibration with isotonic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CalibratedClassifierCV(clf.best_estimator_,\n",
    "                             method='isotonic',\n",
    "                             cv='prefit')\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=clf.predict(X_train),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf,\n",
    "                     X_train,\n",
    "                     y_train,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_train)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_train), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=clf.predict(X_test),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(clf,\n",
    "                     X_test,\n",
    "                     y_test,\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_test)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_test), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(a.predict(b)),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for LinearSVC',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for LinearSVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "Wrapper library *scikeras* provides *scikit-learn* high-level API for *tensorflow*/*keras* underlying library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layer_dim,\n",
    "              dropout_rate,\n",
    "              activation_function,\n",
    "              meta):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(meta['n_features_in_'],\n",
    "                    input_shape=meta['X_shape_'][1:],\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(hidden_layer_dim,\n",
    "                    activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate,\n",
    "                      seed=seed))\n",
    "    model.add(Dense(meta['n_classes_'],\n",
    "                    activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the cross-valudation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'loss': ['categorical_hinge',\n",
    "                   'categorical_crossentropy'],\n",
    "          'activation_function': ['relu',\n",
    "                                  'sigmoid']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(KerasClassifier(get_model,\n",
    "                                   optimizer='adam',\n",
    "                                   dropout_rate=0.2,\n",
    "                                   hidden_layer_dim=757,\n",
    "                                   activation_function='relu',\n",
    "                                   # class_weight='balanced', # causes warnings\n",
    "                                   metrics=Recall,\n",
    "                                   epochs=maxiter,\n",
    "                                   callbacks=early_stopping,\n",
    "                                   validation_split=0.2,\n",
    "                                   batch_size=-1,\n",
    "                                   verbose=0,\n",
    "                                   random_state=seed),\n",
    "                   param_grid=params,\n",
    "                   scoring=lambda a, b: balanced_accuracy_score(ohe.inverse_transform(a),\n",
    "                                                                ohe.inverse_transform(b)),\n",
    "                   cv=cross_validation_generator,\n",
    "                   n_jobs=2)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            ohe.transform(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=ohe.inverse_transform(clf.predict(X_train)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(conf_mat=conf_matrx(y_target=y_train,\n",
    "                                              y_predicted=ohe.inverse_transform(clf.predict(X_train))),\n",
    "                          figsize=(16, 9),\n",
    "                          cmap='Greens',\n",
    "                          show_absolute=False,\n",
    "                          show_normed=True,\n",
    "                          class_names=labels2display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_train)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_train), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=ohe.inverse_transform(clf.predict(X_test)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_confusion_matrix(conf_mat=conf_matrx(y_target=y_test,\n",
    "                                              y_predicted=ohe.inverse_transform(clf.predict(X_test))),\n",
    "                          figsize=(16, 9),\n",
    "                          cmap='Blues',\n",
    "                          show_absolute=False,\n",
    "                          show_normed=True,\n",
    "                          class_names=labels2display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scores = clf.predict_proba(X_test)\n",
    "y_onehot = pd.DataFrame(ohe.transform(y_test), columns=ohe.classes_)\n",
    "\n",
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "for i in range(y_scores.shape[1]):\n",
    "    y_true = y_onehot.iloc[:, i]\n",
    "    y_score = y_scores[:, i]\n",
    "\n",
    "    precision, recall, _ = prec_rec_crve(y_true, y_score)\n",
    "    ap_score = average_precision_score(y_true, y_score)\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "\n",
    "    name = f'{y_onehot.columns[i]} (AP={ap_score:.2f})'\n",
    "    plt.plot(recall, precision, label=name)\n",
    "    \n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_train_sample,\n",
    "                         enc.transform(y_train_sample),\n",
    "                         predict_function=lambda a, b: enc.transform(ohe.inverse_transform(a.predict(b))),\n",
    "                         model_type='classification',\n",
    "                         label='Variable importance measures for KerasClassifier',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(N=sample,\n",
    "                               B=start,\n",
    "                               type='shap_wrapper',\n",
    "                               shap_explainer_type='KernelExplainer',\n",
    "                               loss_function=lambda a, b: 1-balanced_accuracy_score(a, b),\n",
    "                               processes=-1,\n",
    "                               random_state=seed,\n",
    "                               data=X_test,\n",
    "                               silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for KerasClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf.plot(plot_type='bar',\n",
    "            max_display=n_features,\n",
    "            plot_size=(16, 9),\n",
    "            title='Variable importance measures for KerasClassifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aproximate k-Nearest Neighbors\n",
    "\n",
    "A more efficient implementation of k-Nearest Neighbors search than the one given in *scikit-learn*.\n",
    "Initially, I tried various implementations based on HSNW search, but I could not find a library that builds indexer deterministically.\n",
    "*Annoy* indexer might be a bit slower, but at least every time I retrain the classifier, with the same set of parameters, I get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnoyKNN:\n",
    "    _estimator_type = \"classifier\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 weighted=False,\n",
    "                 metric='manhattan',\n",
    "                 k=5,\n",
    "                 n_trees=128,\n",
    "                 n_jobs=1,\n",
    "                 random_state=None):\n",
    "        assert isinstance(weighted, bool), 'weighted has to be bool'\n",
    "        assert metric in ('angular',\n",
    "                          'euclidean',\n",
    "                          'manhattan',\n",
    "                          'hamming',\n",
    "                          'dot'), 'metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"'\n",
    "        assert isinstance(k, int), 'k has to be int'\n",
    "        assert isinstance(n_trees, int), 'n_trees has to be int'\n",
    "        assert isinstance(n_jobs, int), 'n_jobs has to be int'\n",
    "        assert isinstance(random_state, (int, type(None))), 'random_state has to be int or None'\n",
    "        \n",
    "        self.index = None\n",
    "        self.X = pd.DataFrame()\n",
    "        self.y = None\n",
    "        self.classes_ = None\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.n_trees = n_trees\n",
    "        self.n_jobs = n_jobs\n",
    "        self.weighted = weighted\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __sklearn_clone__(self):\n",
    "        clone = AnnoyKNN(self.weighted,\n",
    "                         self.metric,\n",
    "                         self.k,\n",
    "                         self.n_trees,\n",
    "                         self.n_jobs,\n",
    "                         self.random_state)\n",
    "        clone.X = self.X\n",
    "        clone.index = self.index\n",
    "        \n",
    "        return clone\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {'index': self.index,\n",
    "                'y': self.y,\n",
    "                'k': self.k,\n",
    "                'classes_': self.classes_,\n",
    "                'metric': self.metric,\n",
    "                'n_trees': self.n_trees,\n",
    "                'n_jobs': self.n_jobs,\n",
    "                'weighted': self.weighted,\n",
    "                'random_state': self.random_state}\n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        for key, val in params.items():\n",
    "            if key in ('metric',\n",
    "                       'n_trees',\n",
    "                       'random_state'):\n",
    "                self.index = None\n",
    "            self.__dict__[key] = val\n",
    "\n",
    "        assert isinstance(self.weighted, bool), 'weighted has to be bool'\n",
    "        assert self.metric in ('angular',\n",
    "                               'euclidean',\n",
    "                               'manhattan',\n",
    "                               'hamming',\n",
    "                               'dot'), 'metric can be \"angular\", \"euclidean\", \"manhattan\", \"hamming\", or \"dot\"'\n",
    "        assert isinstance(self.k, int), 'k has to be int'\n",
    "        assert isinstance(self.n_trees, int), 'n_trees has to be int'\n",
    "        assert isinstance(self.n_jobs, int), 'n_jobs has to be int'\n",
    "        assert isinstance(self.random_state, (int, type(None))), 'random_state has to be int or None'\n",
    "        assert isinstance(self.X, (pd.DataFrame, np.ndarray)), 'X has to be pandas DataFrame or numpy array object'\n",
    "        self.X = self.X if isinstance(self.X, pd.DataFrame) else pd.DataFrame(self.X)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        assert isinstance(X, (pd.DataFrame, np.ndarray)), 'X has to be pandas DataFrame or numpy array object'\n",
    "        X = X if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        \n",
    "        if self.index is None or not X.equals(self.X):\n",
    "            self.X = X\n",
    "            \n",
    "            self.index = AnnoyIndex(X.shape[1], self.metric)\n",
    "            self.index.set_seed(self.random_state)\n",
    "            \n",
    "            for i, v in enumerate(X.to_numpy()):\n",
    "                self.index.add_item(i, v)\n",
    "            self.index.build(self.n_trees, self.n_jobs)\n",
    "            \n",
    "        assert isinstance(y, (pd.Series, np.ndarray)), 'y has to be pandas Series object'\n",
    "        self.y = y.to_numpy() if isinstance(y, pd.Series) else y\n",
    "        self.classes_ = np.unique(self.y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        assert self.index is not None, 'first to fit the model you have'\n",
    "        assert isinstance(X, (pd.DataFrame, np.ndarray)), 'X has to be pandas DataFrame or numpy array object'\n",
    "        assert isinstance(y, (pd.Series, np.ndarray)), 'y has to be pandas Series or numpy array object'\n",
    "        \n",
    "        return balanced_accuracy_score(y_true=y,\n",
    "                                       y_pred=self.predict(X),\n",
    "                                       sample_weight=sample_weight)\n",
    "\n",
    "    def __get_weighted_votes(self, X):\n",
    "        indices = np.empty((X.shape[0], self.k),\n",
    "                           dtype=np.int32)\n",
    "        distances = np.empty((X.shape[0], self.k),\n",
    "                             dtype=np.float64)\n",
    "        \n",
    "        # Annoy is annoying for not having batch query ...\n",
    "        for i, v in enumerate(X.to_numpy()):\n",
    "            tmp_i, tmp_d = self.index.get_nns_by_vector(v,\n",
    "                                                        self.k,\n",
    "                                                        include_distances=self.weighted)\n",
    "            indices[i] = np.array(tmp_i,\n",
    "                                  dtype=np.int32)\n",
    "            distances[i] = np.array(tmp_d,\n",
    "                                    dtype=np.float64)\n",
    "        \n",
    "        vote = self.y[indices]\n",
    "        weight = np.reciprocal(distances,\n",
    "                               where=distances!=0,\n",
    "                               out=np.zeros_like(distances))\n",
    "        weighted_votes = [(vote[a], weight[a]) for a in range(indices.shape[0])]\n",
    "        \n",
    "        return weighted_votes\n",
    "    \n",
    "    def __get_unweighted_votes(self, X):        \n",
    "        indices = np.empty((X.shape[0], self.k),\n",
    "                           dtype=np.int32)\n",
    "        \n",
    "        # Annoy is annoying for not having batch query ...\n",
    "        for i, v in enumerate(X.to_numpy()):\n",
    "            tmp_i = self.index.get_nns_by_vector(v,\n",
    "                                                 self.k,\n",
    "                                                 include_distances=self.weighted)\n",
    "            indices[i] = np.array(tmp_i,\n",
    "                                  dtype=np.int32)\n",
    "        \n",
    "        unweighted_votes = self.y[indices]\n",
    "        \n",
    "        return unweighted_votes\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert isinstance(X, (pd.DataFrame, np.ndarray)), 'X has to be pandas DataFrame or numpy array object'\n",
    "        X = X if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        predictions = None\n",
    "        \n",
    "        if self.weighted:\n",
    "            votes = self.__get_weighted_votes(X)\n",
    "            \n",
    "            predictions = np.array([np.argmax(np.bincount(a,\n",
    "                                                          weights=b)) for a, b in votes],\n",
    "                                   dtype=np.int32)\n",
    "        else:\n",
    "            votes = self.__get_unweighted_votes(X)\n",
    "            \n",
    "            predictions = np.array([np.argmax(np.bincount(a)) for a in votes],\n",
    "                                   dtype=np.int32)\n",
    "            \n",
    "        return pd.Series(predictions)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        assert isinstance(X, (pd.DataFrame, np.ndarray)), 'X has to be pandas DataFrame or numpy array object'\n",
    "        X = X if isinstance(X, pd.DataFrame) else pd.DataFrame(X)\n",
    "        probabilities = None\n",
    "        \n",
    "        if self.weighted:\n",
    "            votes = self.__get_weighted_votes(X)\n",
    "            \n",
    "            numerator = np.array([np.bincount(a,\n",
    "                                              weights=b,\n",
    "                                              minlength=self.classes_.shape[0]) for a, b in votes])\n",
    "            denominator = np.array([a.sum() for a in numerator])\n",
    "            probabilities = np.array([a / b for a, b in zip(numerator, denominator)])\n",
    "        else:\n",
    "            votes = self.__get_unweighted_votes(X)\n",
    "\n",
    "            numerator = np.array([np.bincount(a,\n",
    "                                              minlength=self.classes_.shape[0]) for a in votes])\n",
    "            denominator = self.k\n",
    "            probabilities = numerator / denominator\n",
    "            \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{'k': [5, 13, 23, 31],\n",
    "          'weighted': [True, False]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying genetic search cross-validation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(AnnoyKNN(n_jobs=-1,\n",
    "                            random_state=seed),\n",
    "                   param_grid=params,\n",
    "                   scoring='balanced_accuracy',\n",
    "                   cv=cross_validation_generator)\n",
    "\n",
    "_ = clf.fit(X_train,\n",
    "            enc.transform(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_best_parameters(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_train,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_train)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(classifier(clf.best_estimator_),\n",
    "                     X_train,\n",
    "                     enc.transform(y_train),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Greens',\n",
    "                     percent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(classifier(clf.best_estimator_),\n",
    "                           X_train,\n",
    "                           enc.transform(y_train),\n",
    "                           classes=labels2display,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test,\n",
    "                            y_pred=enc.inverse_transform(clf.predict(X_test)),\n",
    "                            digits=5,\n",
    "                            zero_division=0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = confusion_matrix(classifier(clf.best_estimator_),\n",
    "                     X_test,\n",
    "                     enc.transform(y_test),\n",
    "                     classes=labels2display,\n",
    "                     cmap='Blues',\n",
    "                     percent=True,\n",
    "                     is_fitted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = precision_recall_curve(classifier(clf.best_estimator_),\n",
    "                           X_test,\n",
    "                           enc.transform(y_test),\n",
    "                           classes=labels2display,\n",
    "                           per_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importances.\n",
    "Since SHAP library dislikes my implementation of AnnoyKNN, and since it's so well documented that it makes debugging impossible, instead of using SHAP values, simple permutation importances will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = dx.Explainer(clf.best_estimator_,\n",
    "                         X_test,\n",
    "                         enc.transform(y_test),\n",
    "                         precalculate=False,\n",
    "                         label='Variable importance measures for AnnoyKNN',\n",
    "                         verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_clf = explainer.model_parts(keep_raw_permutations=False,\n",
    "                               random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mp_clf.result.copy()\n",
    "df = df.set_index('variable')\n",
    "df = df.drop(index=['_baseline_', '_full_model_'])\n",
    "\n",
    "df['dropout_loss'] = df['dropout_loss'] - df['dropout_loss'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(16, 9))\n",
    "\n",
    "_ = sns.barplot(data=df.nlargest(n_features, 'dropout_loss'),\n",
    "                y='variable',\n",
    "                x='dropout_loss',\n",
    "                orient='h',\n",
    "                color='royalblue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "After loading the data, features containing coding sequences and protein types have been extracted.\n",
    "Then, we cleaned up the data by dropping the sequences with inappropriate number of nucleotides, with ambiguities, or belong to the classes represented by too few instances for reliable generalization.\n",
    "\n",
    "The preparation phase has been completed by calculating codon usage frequencies and splitting the data into train and test sets.\n",
    "A couple of other utilities have been prepared, before moving on to visualization phase.\n",
    "\n",
    "During the visualization phase, we first looked at some general statistics.\n",
    "That is, distribution of instances in different classes and features correlation test with target variable.\n",
    "Then we looked at parallel coordinates and radar chart of a sampled data, and finally we looked at *t-SNE* projection of the training dataset.\n",
    "The classes are extremely imbalanced, but they seem to be separable.\n",
    "Then, we moved on to classification.\n",
    "\n",
    "It appears that the data is linearly separable, as the linear-like classifiers such as *LinearSVC* and *DecisionTreeClassifier* achieved excellent results.\n",
    "Even my custom built *AnnoyKNN* classifier, based on *Annoy* indexer, favored fewer neighbors and ignored distances, which implies that it prefers more linear separation of the data.\n",
    "\n",
    "*ComplementaryNB* struggled with imbalanced data.\n",
    "It simply failed to recognize the underrepresented classes.\n",
    "\n",
    "The best results have been achieved with ensemble methods based on decision trees.\n",
    "That doesn't come as a surprise, as even a single decision tree has achieved significant result.\n",
    "\n",
    "This version of *KerasClassifier* appears to be broken.\n",
    "In conjunction with *GASearchCV* it fails to report classification score, which is necessary for triggering early stopping callback.\n",
    "Instead it returned NaN values.\n",
    "When used with ordinary *GridSearchCV* it triggerd a number of warnings for variables that are even not accessible from *scikeras* API.\n",
    "\n",
    "This version of *GASearchCV* does not parallelize at all, despite having n_jobs parameter.\n",
    "If it has to evaluate *n* models during an iteration, and it has *n* cores available, I would expect that it would train each model in a separate process.\n",
    "Instead, the models are trained one at a time, which is a serious flaw of this implementation.\n",
    "\n",
    "Despite imbalance, the data classifies really well.\n",
    "The majority of classifiers have achieved nearly $100\\%$ accuracy, which is very rare.\n",
    "Overall, out of seven reained models, six demonstrated excellent classification performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
